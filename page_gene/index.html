<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png" />
    <link rel="stylesheet" type="text/css" href="assets/main.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gene Research - INCON Group</title>
    
    <link href="https://fonts.googleapis.com/css?family=Roboto%7CRoboto+Slab" rel="stylesheet">

    <style>
        /* 针对论文列表的特定样式，仅在此页面生效 */
        .paper-list {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .paper-item {
            display: flex;
            align-items: flex-start;
            margin-bottom: 35px;
            gap: 25px;
            padding-bottom: 25px;
            border-bottom: 1px solid #f0f0f0;
        }

        .paper-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
        }

        .paper-preview-img {
            width: 180px; 
            height: 120px; 
            object-fit: cover; 
            border: 1px solid #ddd;
            border-radius: 4px;
            flex-shrink: 0;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        }

        .paper-content {
            flex: 1;
            min-width: 0;
        }

        .paper-title {
            font-size: 1.25rem;
            font-weight: bold;
            color: var(--primary-blue, #003B5C);
            margin-bottom: 8px;
            display: block;
            line-height: 1.4;
        }

        .paper-author {
            font-style: italic;
            display: block;
            margin-bottom: 10px;
            color: #555;
            font-size: 0.95rem;
        }

        .paper-desc {
            font-size: 0.95rem;
            color: #444;
            line-height: 1.6;
            margin-bottom: 15px;
            text-align: justify;
            display: block;
        }

        .paper-links a {
            color: var(--accent-blue, #52739e);
            text-decoration: none;
            font-weight: bold;
            font-size: 0.9rem;
        }

        .paper-links a:hover {
            text-decoration: underline;
            color: #b2132e;
        }

        @media (max-width: 768px) {
            .paper-item {
                flex-direction: column;
                align-items: center;
                text-align: center;
            }
            .paper-preview-img {
                width: 100%;
                max-width: 300px;
                height: auto;
            }
        }
    </style>
</head>

<body>

    <div class="banner">
        <div class="page-container">
            <h1>INCON Group</h1>
            <p>Intelligent Neuroimaging for Computational Neuroscience</p>
        </div>
    </div>

    <div class="navigation-wrap">
        <div class="page-container">
            <table class="navigation">
                <tr>
                    <td><a href="index.html">Home</a></td>
                    <td><a title="News" href="page_news.html">News</a></td>
                    <td><a title="MRI" href="page_mri/index.html">Neuroimaging </a></td>
                    <td><a title="Tissue" href="page_tissue/index.html">Tissue Imaging</a></td>
                    <td><a class="current" title="Gene" href="page_gene/index.html">Imaging Genetics </a></td>
                    <td><a title="Demo" href="page_demo/index.html">Clinical Translation </a></td>
                </tr>
            </table>
        </div>
    </div>

    <div class="page-container">
        
        <section id="Published"><!--PublishedPublishedPublishedPublishedPublishedPublishedPublishedPublishedPublishedPublishedPublishedPublishedPublishedPublished-->
            <h2>Published Works</h2>
            <ul class="paper-list"></ul>
                <li class="paper-item">
                    <img src="doc/gene/p/Knowledge-driven Subspace Fusion and.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Knowledge-Driven Subspace Fusion and Gradient Coordination for Multi-modal Learning</span>
                        <span class="paper-journal">Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023)</span>
                        <span class="paper-author">Yupei Zhang, Xiaofei Wang, Fangliangzi Meng, Jin Tang, and Chao Li*</span>
                        <p class="paper-desc">A knowledge-driven multi-modal framework is proposed that models tumour and TME gene subspaces and improves glioma diagnosis, grading, and survival prediction through cross-modal deformable attention and gradient coordination.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/p/paper01.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/helenypzhang/Subspace-Multimodal-Learning" target="_blank">Code</a>
                        </div>
                    </div>
                </li>
                
                <li class="paper-item">
                    <img src="doc/gene/p/Genomics-Guided Representation Learning for Pathologic Pan-Cancer Tumor Microenvironment Subtype Prediction.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content">
                        <span class="paper-title">Genomics-Guided Representation Learning for Pathologic Pan-Cancer Tumor Microenvironment Subtype Prediction</span>
                        <span class="paper-journal">MICCAI 2024</span>
                        <span class="paper-author">Fangliangzi Meng, Hongrun Zhang, Ruodan Yan, Guohui Chuai, Chao Li & Qi Liu</span>
                        
                        <p class="paper-desc">.</p>
                        
                        <div class="paper-links">
                            <a href="https://link.springer.com/chapter/10.1007/978-3-031-72384-1_20" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>
                        </div>
                    </div>
                </li>

            <!--
                <li class="paper-item">
                    <img src="doc/[子页面关键词]/p/你的图片名.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content">
                        <span class="paper-title">这里输入你的论文标题</span>
                        <span class="paper-journal">发表/投稿期刊（预印本写Preprint）</span>
                        <span class="paper-author">作者姓名</span>
                        
                        <p class="paper-desc">请简要描述这项工作的核心创新点和贡献（建议 2-3 句话）。</p>
                        
                        <div class="paper-links">
                            <a href="doc/[子页面关键词]/p/你的论文.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>
                        </div>
                    </div>
                </li>
            -->

                
                <li class="paper-item">
                    <img src="doc/gene/p/Unified Modeling Enhanced Multimodal Learning.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content">
                        <span class="paper-title">Unified Modeling Enhanced Multimodal Learning for Precision Neuro-Oncology</span>
                        <span class="paper-journal">Medical Image Computing and Computer Assisted Intervention (MICCAI 2024)</span>
                        <span class="paper-author">Huahui Yi, Xiaofei Wang, Kang Li, Chao Li</span>
                        
                        <p class="paper-desc">This work proposes a unified multimodal framework for neuro-oncology. Enhanced modeling improves precision diagnosis and prognosis. The approach integrates heterogeneous medical data effectively.</p>
                        
                        <div class="paper-links">
                            <a href="doc/gene/p/Unified Modeling Enhanced Multimodal Learning.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                
                <li class="paper-item">
                    <img src="doc/gene/p/Adaptive Spatial Transcriptomics Interpolation.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Adaptive Spatial Transcriptomics Interpolation via Cross-modal Cross-slice Modeling</span>
                        <span class="paper-journal">International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2025)</span>
                        <span class="paper-author">Ningfeng Que, Xiaofei Wang, Jingjing Chen, Yixuan Jiang, Chao Li*</span>
                        <p class="paper-desc">This work addresses spatial transcriptomics interpolation across tissue slices. A cross-modal and cross-slice modeling strategy is proposed. The method enables flexible ST reconstruction with arbitrary slice numbers.</p>
                        <div class="paper-links">
                            <a href="https://arxiv.org/pdf/2505.10729" target="_blank">Paper</a> |
                            <a href="https://github.com/XiaofeiWang2018/C2-STi" target="_blank">Code</a>
                        </div>
                    </div>
                </li>
            </ul>
        </section>

        <section id="UR"><!--URURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURURUR-->
            <h2>Under Review / Preprint</h2>
            <ul class="paper-list">
                <li class="paper-item"><!--boxing glycemic-->
                    <img src="doc/gene/p/glycemic.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content">
                        <span class="paper-title">Genetics-informed bidirectional mapping of glycemic traits and brain phenotypes</span>
                        <span class="paper-journal">Preprint</span>
                        <span class="paper-author">Boxing Liu, Yunfan Zhang, Jianwei Chen, and Chao Li</span>
                        
                        <p class="paper-desc">In this study, we investigated the directional effect between glycemic traits and brain phenotypes via integrating GWAS of glycemic traits, 
                            multimodal neuroimaging, and neuropsychiatric disorders within a genetic-informed framework with bidirectional two-sample Mendelian randomization (MR). 
                            Additionally, eQTL-based, cell- and tissue-resolved annotation localizes these signals to specific biological pathways and brain cells. 
                            This provided an integrative foundation for understanding how glycemic variation aligns with brain architecture and contributes to the risk of neuropsychiatric disorders,
                            enabling us to construct a prevention scenario.</p>
                        
                        <div class="paper-links">
                            <a href="https://doi.org/10.64898/2026.01.08.698365" target="_blank">Paper</a> |
                            <a href="https://github.com/zaqwedcx-lgtm/Glycemic/tree/main" target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/gene/p/Interpretable Multimodal Cancer Prototyping.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Interpretable Multimodal Cancer Prototyping with Whole Slide Images and Incompletely Paired Genomics</span>
                        <span class="paper-journal">IEEE Transactions on Medical Imaging (TMI)</span>
                        <span class="paper-author">Yupei Zhang, Yating Huang, Wanming Hu, Lequan Yu, Hujun Yin, Chao Li*</span>
                        <p class="paper-desc">An interpretable multimodal framework is proposed that combines prototype-based modeling, multiview alignment, and bipartite fusion to integrate WSIs with incompletely paired genomics for robust cancer prediction.</p>
                        <div class="paper-links">
                            <a href="doc/gene/p/Interpretable Multimodal Cancer Prototyping.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/helenypzhang/Interpretable-Multimodal-Prototyping" target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item"><!--PA analysis-->
                    <img src="doc/gene/p/PA.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content">
                        <span class="paper-title">Objectively measured multidimensional behaviour profiles and brain health</span>
                        <span class="paper-journal">Preprint</span>
                        
                        <p class="paper-desc">Utilizing the wristband accelerometer data of approximately 90,000 subjects in the UK Biobank to deeply explore the characteristics of individuals' Physical Activity,
                            Sleep and Circadian Rhythm. The core objective of the research is to quantify how these daily behavioral characteristics reflect or predict complex brain health phenotypes, 
                            including neuropsychiatric disorders, cognitive functions, and changes in brain structure. 
                            83 features were integrated into 17 principal components to distinguish the common variations and independent variations among behaviors through the Joint and Individual Variation Explained (JIVE) method</p>
                        
                        <div class="paper-links">
                            <a href="doc/[子页面关键词]/p/你的论文.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/LHY1007/INCON/tree/main/doc/gene/code/PA" target="_blank">Code</a>
                        </div>
                    </div>
                </li>               
            </ul>
        </section>
        
    </div>

    <footer>
        <div class="page-container">
            &copy; 2025 Intelligent Neuroimaging for Computational Neuroscience | University of Cambridge
        </div>
    </footer>

</body>
</html>
