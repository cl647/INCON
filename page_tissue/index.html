<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png" />
    <link rel="stylesheet" type="text/css" href="assets/main.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gene Research - INCON Group</title>
    
    <link href="https://fonts.googleapis.com/css?family=Roboto%7CRoboto+Slab" rel="stylesheet">

    <style>
        /* 针对论文列表的特定样式，仅在此页面生效 */
        .paper-list {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .paper-item {
            display: flex;
            align-items: flex-start;
            margin-bottom: 35px;
            gap: 25px;
            padding-bottom: 25px;
            border-bottom: 1px solid #f0f0f0;
        }

        .paper-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
        }

        .paper-preview-img {
            width: 180px; 
            height: 120px; 
            object-fit: cover; 
            border: 1px solid #ddd;
            border-radius: 4px;
            flex-shrink: 0;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        }

        .paper-content {
            flex: 1;
            min-width: 0;
        }

        .paper-title {
            font-size: 1.25rem;
            font-weight: bold;
            color: var(--primary-blue, #003B5C);
            margin-bottom: 8px;
            display: block;
            line-height: 1.4;
        }

        .paper-author {
            font-style: italic;
            display: block;
            margin-bottom: 10px;
            color: #555;
            font-size: 0.95rem;
        }

        .paper-desc {
            font-size: 0.95rem;
            color: #444;
            line-height: 1.6;
            margin-bottom: 15px;
            text-align: justify;
            display: block;
        }

        .paper-links a {
            color: var(--accent-blue, #52739e);
            text-decoration: none;
            font-weight: bold;
            font-size: 0.9rem;
        }

        .paper-links a:hover {
            text-decoration: underline;
            color: #b2132e;
        }

        @media (max-width: 768px) {
            .paper-item {
                flex-direction: column;
                align-items: center;
                text-align: center;
            }
            .paper-preview-img {
                width: 100%;
                max-width: 300px;
                height: auto;
            }
        }
    </style>
</head>

<body>

    <div class="banner">
        <div class="page-container">
            <h1>INCON Group</h1>
            <p>Intelligent Neuroimaging for Computational Neuroscience</p>
        </div>
    </div>

    <div class="navigation-wrap">
        <div class="page-container">
            <table class="navigation">
                <tr>
                    <td><a href="index.html">Home</a></td>
                    <td><a title="MRI" href="page_mri/index.html">Neuroimaging </a></td>
                    <td><a class="current" title="Tissue" href="page_tissue/index.html">Tissue Imaging </a></td>
                    <td><a title="Gene" href="page_gene/index.html">Imaging Genetics </a></td>
                    <td><a title="Demo" href="page_demo/index.html">Clinical Translation </a></td>
                </tr>
            </table>
        </div>
    </div>

    <div class="page-container">
        <section id="Published">
            <h2>Published Works</h2>
            <ul class="paper-list">
                <li class="paper-item">
                    <img src="doc/page_tissue/p/placeholder.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">这里输入你的论文标题</span>
                        <span class="paper-journal">发表/投稿期刊（预印本写Preprint）</span>
                        <span class="paper-author">作者姓名</span>
                        <p class="paper-desc">请简要描述这项工作的核心创新点和贡献（建议 2-3 句话）。</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/p/placeholder.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/p/paper01.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Knowledge-Driven Subspace Fusion and Gradient Coordination for Multi-modal Learning</span>
                        <span class="paper-journal">Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023)</span>
                        <span class="paper-author">Yupei Zhang, Xiaofei Wang, Fangliangzi Meng, Jin Tang, and Chao Li*</span>
                        <p class="paper-desc">A knowledge-driven multi-modal framework is proposed that models tumour and TME gene subspaces and improves glioma diagnosis, grading, and survival prediction through cross-modal deformable attention and gradient coordination.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/p/paper01.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/helenypzhang/Subspace-Multimodal-Learning" target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/p/paper02.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Joint Modeling Histology and Molecular Markers for Cancer Classification</span>
                        <span class="paper-journal">Medical Image Analysis (MIA 2025, IF=14.94)</span>
                        <span class="paper-author">Xiaofei Wang, Hanyu Liu, Yupei Zhang, Boyang Zhao, Hao Duan, Wanming Hu, Yonggao Mou, Stephen Price, Chao Li*</span>
                        <p class="paper-desc">This work jointly models histology and molecular markers for cancer classification. A multi-task learning framework is designed for cross-modal prediction. Strong performance is achieved on multiple cancer datasets.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/p/paper02.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/LHY1007/M3C2.git" target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/p/paper03.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Score-Based Diffusion Model for Unpaired Virtual Histology Staining</span>
                        <span class="paper-journal">Computational Mathematics Modeling in Cancer Analysis (CMMCA 2025)</span>
                        <span class="paper-author">Anran Liu, Xiaofei Wang, Jing Cai*, Chao Li*</span>
                        <p class="paper-desc">This paper introduces a score-based diffusion framework for unpaired virtual staining. The model learns cross-modal mappings between H&E and IHC images. It enables realistic virtual histology without paired supervision.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/p/paper03.pdf" target="_blank">Paper</a> |
                            <a href="javascript:void(0)">Code is being organized</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/p/paper04.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Adaptive Spatial Transcriptomics Interpolation via Cross-modal Cross-slice Modeling</span>
                        <span class="paper-journal">International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2025)</span>
                        <span class="paper-author">Ningfeng Que, Xiaofei Wang, Jingjing Chen, Yixuan Jiang, Chao Li*</span>
                        <p class="paper-desc">This work addresses spatial transcriptomics interpolation across tissue slices. A cross-modal and cross-slice modeling strategy is proposed. The method enables flexible ST reconstruction with arbitrary slice numbers.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/p/paper04.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/XiaofeiWang2018/C2-STi" target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/p/paper05.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Cross-modal Diffusion Modelling for Super-resolved Spatial Transcriptomics</span>
                        <span class="paper-journal">Medical Image Computing and Computer Assisted Intervention (MICCAI 2024)</span>
                        <span class="paper-author">Xiaofei Wang, Xingxu Huang, Stephen Price, Chao Li*</span>
                        <p class="paper-desc">This paper proposes a diffusion-based model for ST super-resolution using histology. Cross-modal guidance improves spatial detail and gene expression fidelity. The approach advances generative modeling for spatial omics.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/p/paper05.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/XiaofeiWang2018/Diffusion-ST" target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/p/paper06.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Unified Modeling Enhanced Multimodal Learning for Precision Neuro-Oncology</span>
                        <span class="paper-journal">Medical Image Computing and Computer Assisted Intervention (MICCAI 2024)</span>
                        <span class="paper-author">Huahui Yi, Xiaofei Wang, Kang Li, Chao Li*</span>
                        <p class="paper-desc">This work proposes a unified multimodal framework for neuro-oncology. Enhanced modeling improves precision diagnosis and prognosis. The approach integrates heterogeneous medical data effectively.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/p/paper06.pdf" target="_blank">Paper</a> |
                            <a href="javascript:void(0)">Code is being organized</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/p/paper07.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Multi-task Learning of Histology and Molecular Markers for Classifying Diffuse Glioma</span>
                        <span class="paper-journal">Medical Image Computing and Computer Assisted Intervention (MICCAI 2023)</span>
                        <span class="paper-author">Xiaofei Wang, Stephen Price, Chao Li*</span>
                        <p class="paper-desc">The paper proposes a multi-task framework for glioma classification. Histology and molecular markers are jointly learned. The method achieves strong performance and clinical relevance.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/p/paper07.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/XiaofeiWang2018/DeepMO-Glioma-Code" target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/p/paper08.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Domain Game: Disentangle Anatomical Feature for Single Domain Generalized Segmentation</span>
                        <span class="paper-journal">Computational Mathematics Modeling in Cancer Analysis (CMMCA 2024)</span>
                        <span class="paper-author">Hao Chen, Hongrun Zhang, U. Wang Chan, Rui Yin, Xiaofei Wang, Chao Li*</span>
                        <p class="paper-desc">This paper studies domain generalization in medical image segmentation. A disentanglement-based strategy is proposed for anatomical features. The method improves robustness under domain shift.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/p/paper08.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/chqwer2/Domain-Game" target="_blank">Code</a>
                        </div>
                    </div>
                </li>
            </ul>
        </section>



        <section id="UR">
            <h2>Under Review / Preprint</h2>
            <ul class="paper-list">
                <li class="paper-item">
                    <img src="doc/page_tissue/ur/placeholder.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">这里输入你的论文标题</span>
                        <span class="paper-journal">发表/投稿期刊（预印本写Preprint）</span>
                        <span class="paper-author">作者姓名</span>
                        <p class="paper-desc">请简要描述这项工作的核心创新点和贡献（建议 2-3 句话）。</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/ur/placeholder.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/ur/paper01.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Disentangled Multi-modal Learning of Histology and Transcriptomics for Cancer Characterization</span>
                        <span class="paper-journal">IEEE Transactions on Medical Imaging (TMI) (IF=11.16)</span>
                        <span class="paper-author">Yupei Zhang, Xiaofei Wang, Anran Liu, Lequan Yu, Chao Li*</span>
                        <p class="paper-desc">This work proposes a disentangled multi-modal framework that decomposes histology and transcriptomics into tumour and TME subspaces and integrates selective multi-modal fusion, gradient coordination, and subspace knowledge distillation to improve cancer diagnosis while enabling WSI-only inference.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/ur/paper01.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/helenypzhang/Disentangled-Multimodal-Learning.git" target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/ur/paper02.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Interpretable Multimodal Cancer Prototyping with Whole Slide Images and Incompletely Paired Genomics</span>
                        <span class="paper-journal">IEEE Transactions on Medical Imaging (TMI)</span>
                        <span class="paper-author">Yupei Zhang, Yating Huang, Wanming Hu, Lequan Yu, Hujun Yin, Chao Li*</span>
                        <p class="paper-desc">An interpretable multimodal framework is proposed that combines prototype-based modeling, multiview alignment, and bipartite fusion to integrate WSIs with incompletely paired genomics for robust cancer prediction.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/ur/paper02.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/helenypzhang/Interpretable-Multimodal-Prototyping" target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/ur/paper03.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">Towards Real-world Molecular Pathology Diagnosis of Cancer with Cross-modal AI</span>
                        <span class="paper-journal">Nature Medicine (Preprint)</span>
                        <span class="paper-author">Xiaofei Wang, Yinyan Wang, Wanming Hu, Mayen Briggs, Zeya Yan, Jie Hu, Yupei Zhang, Hao Duan, Stephen Price*, Chao Li*</span>
                        <p class="paper-desc">This work targets real-world molecular pathology by jointly modeling histology and molecular data. It focuses on robustness, clinical translation, and large-scale multi-cohort validation, demonstrating strong generalization in diagnostic settings.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/ur/paper03.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/XiaofeiWang2018/CAMPaS.git" target="_blank">Code</a>
                        </div>
                    </div>
                </li>

                <li class="paper-item">
                    <img src="doc/page_tissue/ur/paper04.png" alt="Preview" class="paper-preview-img">
                    <div class="paper-content">
                        <span class="paper-title">C3-Diff: Super-resolving Spatial Transcriptomics via Cross-modal Cross-content Contrastive Diffusion Modeling</span>
                        <span class="paper-journal">IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2026 (Under Review)</span>
                        <span class="paper-author">Xiaofei Wang, Stephen Price, Chao Li*</span>
                        <p class="paper-desc">This paper proposes a diffusion-based framework for super-resolving spatial transcriptomics using histology guidance. Cross-content contrastive learning is introduced to improve resolution and biological consistency of ST data.</p>
                        <div class="paper-links">
                            <a href="doc/page_tissue/ur/paper04.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/XiaofeiWang2018/C3-Diff.git" target="_blank">Code</a>
                        </div>
                    </div>
                </li>
            </ul>
        </section>
    </div>

    <footer>
        <div class="page-container">
            &copy; 2025 Intelligent Neuroimaging for Computational Neuroscience | University of Cambridge
        </div>
    </footer>

</body>
</html>