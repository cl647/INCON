<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png" />
    <link rel="stylesheet" type="text/css" href="assets/main.css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gene Research - INCON Group</title>
    
    <link href="https://fonts.googleapis.com/css?family=Roboto%7CRoboto+Slab" rel="stylesheet">

    <style>
        /* 针对论文列表的特定样式，仅在此页面生效 */
        .paper-list {
            list-style: none;
            padding: 0;
            margin: 0;
        }

        .paper-item {
            display: flex;
            align-items: flex-start;
            margin-bottom: 35px;
            gap: 25px;
            padding-bottom: 25px;
            border-bottom: 1px solid #f0f0f0;
        }

        .paper-item:last-child {
            border-bottom: none;
            margin-bottom: 0;
        }

        .paper-preview-img {
            width: 180px; 
            height: 120px; 
            object-fit: cover; 
            border: 1px solid #ddd;
            border-radius: 4px;
            flex-shrink: 0;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
        }

        .paper-content {
            flex: 1;
            min-width: 0;
        }

        .paper-title {
            font-size: 1.25rem;
            font-weight: bold;
            color: var(--primary-blue, #003B5C);
            margin-bottom: 8px;
            display: block;
            line-height: 1.4;
        }

        .paper-author {
            font-style: italic;
            display: block;
            margin-bottom: 10px;
            color: #555;
            font-size: 0.95rem;
        }

        .paper-desc {
            font-size: 0.95rem;
            color: #444;
            line-height: 1.6;
            margin-bottom: 15px;
            text-align: justify;
            display: block;
        }

        .paper-links a {
            color: var(--accent-blue, #52739e);
            text-decoration: none;
            font-weight: bold;
            font-size: 0.9rem;
        }

        .paper-links a:hover {
            text-decoration: underline;
            color: #b2132e;
        }

        /*自己加了一段*/
        .paper-journal-muted {
            color: #999;
            font-style: italic;
        }

        @media (max-width: 768px) {
            .paper-item {
                flex-direction: column;
                align-items: center;
                text-align: center;
            }
            .paper-preview-img {
                width: 100%;
                max-width: 300px;
                height: auto;
            }
        }
    </style>
</head>

<body>

    <div class="banner">
        <div class="page-container">
            <h1>INCON Group</h1>
            <p>Intelligent Neuroimaging for Computational Neuroscience</p>
        </div>
    </div>

    <div class="navigation-wrap">
        <div class="page-container">
            <table class="navigation">
                <tr>
                    <td><a href="index.html">Home</a></td>
                    <td><a title="News" href="page_news/index.html">News</a></td>
                    <td><a class="current" title="MRI" href="page_mri/index.html">Neuroimaging </a></td>
                    <td><a title="Tissue" href="page_tissue/index.html">Tissue Imaging </a></td>
                    <td><a title="Gene" href="page_gene/index.html">Imaging Genetics </a></td>
                    <td><a title="Demo" href="page_demo/index.html">Clinical Translation </a></td>
                </tr>
            </table>
        </div>
    </div>

    <div class="page-container">
        
        <section id="Published">
            <h2>Published Works</h2>
            <ul class="paper-list"></ul>
                <li class="paper-item"><!--开始-->
                    <img src="doc/mri/p/GLNO.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content"><!--tanghao的GLNO-->
                        <span class="paper-title">Geometric Laplace Neural Operator</span>
                        <span class="paper-journal">arXiv</span>
                        <span class="paper-author">Hao Tang, Jiongyu Zhu, Zimeng Feng, Hao Li, Chao Li</span>
                        
                        <p class="paper-desc">
                            The proposed framework takes functions defined on arbitrary geometries as input and learns a resolution-invariant operator mapping. 
                            It first models aperiodic and decaying dynamics using a Laplace-domain pole–residue representation with exponential bases, 
                            then embeds this representation into the Laplace–Beltrami eigenbasis to handle non-Euclidean domains. 
                            A grid-invariant neural architecture (GLNONet) is designed to realize this operator in practice, enabling robust operator learning across PDEs, ODEs, 
                            and real-world datasets.
                        </p>
                        
                        <div class="paper-links">
                            <a href="doc/mri/p/tanghao_GLNO.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>
                        </div>
                    </div>
                </li><!--结束-->


                <li class="paper-item"><!--开始-->
                    <img src="doc/mri/p/jianwei_image.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content"><!--建玮的-->
                        <span class="paper-title">Multiscale Causal Geometric Deep Learning for Modeling Brain Structure</span>
                        <span class="paper-journal">arXiv</span>
                        <!--<span class="paper-journal">发表/投稿期刊（预印本写Preprint）</span>-->
                        <span class="paper-author">Chengzhi Xia* Jianwei Chen* Yixuan Jiang Qi Yan Chao Li</span>
                        
                        <p class="paper-desc">
                            Devised a geometric deep learning model to introduce Laplacian harmonics and spectral graph theory to optimize multimodal alignment and multiscale integration.
                            Graph Variational Autoencoder architectures is used in disentangled learning to distinguish shared features from latent space and scale-specific features
                            Modelling eigenvectors from different modalities data in the Laplacian spectral domain with multiscale interpretation
                            causal and non-causal factors are distinguished by a mutual information-informed bilevel regularizer
                        </p>
                        
                        <div class="paper-links">
                            <a href="doc/mri/p/jianwei_archive.pdf" target="_blank">Paper</a>
                            <!--<a href="doc/[子页面关键词]/p/你的论文.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>-->
                        </div>
                    </div>
                </li><!--结束-->

                <li class="paper-item"><!--开始-->
                    <img src="doc/mri/p/FOD-Diff.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content"><!--tanghao的FOD-Diff-->
                        <span class="paper-title">Multiscale Causal Geometric Deep Learning for Modeling Brain Structure</span>
                        <span class="paper-journal">arXiv</span>
                        <!--<span class="paper-journal">发表/投稿期刊（预印本写Preprint）</span>-->
                        <span class="paper-author">Hao Tang, Hanyu Liu, Alessandro Perelli, Xi Chen, Chao Li</span>
                        
                        <p class="paper-desc">
                            We propose a 3D multi-channel patch-based diffusion model for predicting HAR-FOD from LAR-FOD, incorporating anatomy-aware patch adaptation, voxel-level conditional coordination, 
                            and harmonic-domain attention to model complex SH coefficient dependencies, achieving state-of-the-art reconstruction performance.
                        </p>
                        
                        <div class="paper-links">
                            <a href="doc/mri/p/tanghaoFOD-Diff.pdf" target="_blank">Paper</a>
                            <!--<a href="doc/[子页面关键词]/p/你的论文.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>-->
                        </div>
                    </div>
                </li><!--结束-->

                <li class="paper-item"><!--开始-->
                    <img src="doc/mri/p/GSNO.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content"><!--tanghao的GSNO-->
                        <span class="paper-title">Multiscale Causal Geometric Deep Learning for Modeling Brain Structure</span>
                        <span class="paper-journal">arXiv</span>
                        <!--<span class="paper-journal">发表/投稿期刊（预印本写Preprint）</span>-->
                        <span class="paper-author">Hao Tang,   Hao Chen,   Chao Li</span>
                        
                        <p class="paper-desc">
                            This work introduces a principled spherical operator-learning framework based on designable Green’s functions and harmonic expansion. 
                            By incorporating absolute and relative position-dependent Green’s functions, the proposed GSNO flexibly balances rotational equivariance and invariance, 
                            enabling effective modeling of anisotropic and constraint-rich systems on the sphere. A hierarchical spectral architecture, GSHNet, 
                            further enhances multi-scale global representation, resulting in consistent performance gains across diverse spherical learning tasks.
                        </p>
                        
                        <div class="paper-links">
                            <a href="doc/mri/p/唐浩GSNO.pdf" target="_blank">Paper</a>
                            <!--<a href="doc/[子页面关键词]/p/你的论文.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>-->
                        </div>
                     </div>
                </li><!--结束-->

                <li class="paper-item"><!--开始-->
                    <img src="doc/mri/p/CoLa-Diff overview.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content"><!--CoLa-Diff-->
                        <span class="paper-title">CoLa-Diff: Conditional Latent Diffusion Model for Multi-Modal MRI Synthesis</span>
                        <span class="paper-journal">arXiv</span>
                        <!--<span class="paper-journal">发表/投稿期刊（预印本写Preprint）</span>-->
                        <span class="paper-author">Lan Jiang, Ye Mao, Xi Chen, Xiangfeng Wang, and Chao Li</span>
                        
                        <p class="paper-desc">
                            CoLa-Diff is a diffusion-based multi-modal MRI synthesis framework that operates in latent space to reduce memory consumption while enabling effective multi-condition modeling.
                            By incorporating cooperative latent filtering, anatomical priors via brain region masks, and adaptive weighting of multi-modal inputs, 
                            CoLa-Diff achieves structure-preserving and high-quality MRI synthesis, outperforming existing state-of-the-art methods.
                        </p>
                        
                        <div class="paper-links">
                            <a href="doc/mri/p/CoLa-Diff.pdf" target="_blank">Paper</a>
                            <!--<a href="doc/[子页面关键词]/p/你的论文.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>-->
                        </div>
                     </div>
                </li><!--结束-->

                <li class="paper-item"><!--开始-->
                    <img src="doc/mri/p/DisC-Diff.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content"><!--DisC-Diff-->
                        <span class="paper-title">DisC-Diff: Disentangled Conditional Diffusion Model for Multi-Contrast MRI Super-Resolution</span>
                        <span class="paper-journal">arXiv</span>
                        <!--<span class="paper-journal">发表/投稿期刊（预印本写Preprint）</span>-->
                        <span class="paper-author">Ye Mao, Lan Jiang, Xi Chen, and Chao Li</span>
                        
                        <p class="paper-desc">
                            DisC-Diff takes low-resolution, multi-contrast brain MRI images as input and employs a conditional diffusion model to generate high-resolution reconstructions while estimating restoration uncertainty. 
                            Within this framework, a multi-stream disentangled network processes different contrasts separately to fully leverage complementary information, 
                            enhancing both reconstruction accuracy and model interpretability. The output is high-resolution, 
                            multi-contrast MRI images along with uncertainty estimates, demonstrating superior quantitative and visual performance compared to existing methods.
                        </p>
                        
                        <div class="paper-links">
                            <a href="doc/mri/p/DisC-Diff.pdf" target="_blank">Paper</a>
                            <!--<a href="doc/[子页面关键词]/p/你的论文.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>-->
                        </div>
                     </div>
                </li><!--结束-->

                <li class="paper-item"><!--开始-->
                    <img src="doc/mri/p/D-CoRP.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content"><!--D-CoRP-->
                        <span class="paper-title">D-CoRP: Differentiable Connectivity Refinement for Functional Brain Networks</span>
                        <span class="paper-journal">arXiv</span>
                        <!--<span class="paper-journal">发表/投稿期刊（预印本写Preprint）</span>-->
                        <span class="paper-author">Haoyu Hu, Hongrun Zhang, and Chao Li</span>
                        
                        <p class="paper-desc">
                            We proposed D-CoRP, a lightweight, plug-in module for refining noisy fMRI-derived functional connectomes so that downstream GNNs learn from more informative graph. 
                            First we generate selection probabilities for each connection by using an auxiliary attention-based module to score how likely an edge is to be kept. 
                            Then we propose differentiable sampling to turn those probabilities into a near-binary masking matrix, so the model can actually “select” edges while still allowing gradients to flow. 
                            Finally, we optimise the mask with an information-bottleneck objective, 
                            encouraging the refined graph to retain task-relevant connectivity but compress away redundant or noisy links.
                        </p>
                        
                        <div class="paper-links">
                            <a href="doc/mri/p/D-CoRP.pdf" target="_blank">Paper</a>
                            <!--<a href="doc/[子页面关键词]/p/你的论文.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>-->
                        </div>
                     </div>
                </li><!--结束-->

                <li class="paper-item"><!--开始-->
                    <img src="doc/mri/p/Phy-Diff.png" alt="Preview" class="paper-preview-img">
                    
                    <div class="paper-content"><!--Phy-Diff-->
                        <span class="paper-title">Phy-Diff: Physics-guided Hourglass Diffusion Model for Diffusion MRI Synthesis</span>
                        <span class="paper-journal">arXiv</span>
                        <!--<span class="paper-journal">发表/投稿期刊（预印本写Preprint）</span>-->
                        <span class="paper-author">Juanhua Zhang , Ruodan Yan , Alessandro Perelli, Xi Chen , and Chao Li</span>
                        
                        <p class="paper-desc">
                            We proposed Phy-Diff, a physics-guided conditional diffusion model for synthesising DWI from b0 under specified b-value/b-vector conditions, 
                            aiming to reduce acquisition while keeping tract-level detail. 
                            We use a physics-guided noise evolution (ADC-informed) to make the forward noising follow diffusion signal attenuation rather than generic Gaussian corruption. 
                            Then we apply query-based conditional mapping to encode continuous b-value and direction so the reverse process can generate DWI for arbitrary q-space settings. 
                            Finally, the designed XTRACT condition adaptation injects tract priors via an adaptor branch to preserve white-matter bundle structure and reduce over-smoothing.
                        </p>
                        
                        <div class="paper-links">
                            <a href="doc/mri/p/Phy-Diff.pdf" target="_blank">Paper</a>
                            <!--<a href="doc/[子页面关键词]/p/你的论文.pdf" target="_blank">Paper</a> |
                            <a href="https://github.com/..." target="_blank">Code</a>-->
                        </div>
                     </div>
                </li><!--结束-->
            </ul>
        </section>
        
    </div>

    <footer>
        <div class="page-container">
            &copy; 2025 Intelligent Neuroimaging for Computational Neuroscience | University of Cambridge
        </div>
    </footer>

</body>
</html>
